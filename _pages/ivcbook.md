---
layout: page
title: Intelligent Image and Video Compression
description: Communicating Pictures, 2nd Edition
nav: false
permalink: /IVC-book/
profile:
  align: right
  image: book_cover_new.svg
  image_circular: false # crops the image to make it circular
---

This book explains the requirements, analysis, design and application of a modern video coding system. It draws on the authors' extensive academic and professional experience in this field to deliver a text that is algorithmically rigorous yet accessible, relevant to modern standards and practical. It builds on a thorough grounding in mathematical foundations and visual perception to demonstrate how modern image and video compression methods can be designed to meet the rate-quality performance levels demanded by today's applications and users, in the context of prevailing network constraints.


## tutorial solutions

[[DOWNLOAD]](/assets/pdf/CP2e_tutorial_solutions_v2.pdf) tutoral solutions.


## demonstration software 

VISTRA is a demonstration software which provides an interactive overview of the some of the key principles of image and video compression, including:

- Spatial and temporal redundancy
- Colour channel subsampling
- JPEG image compression
- DCT transform coding
- Motion compensated video compression
- Motion estimation block matching

The software and user manual can be downloaded from [here](/assets/zips/VISTRA-IVC.zip).

We have also developed a mini demo software for DCT, which can be download from [here](/assets/zips/DCT_demo.zip).

## key features

- An approach that combines algorithmic rigor with practical implementation using numerous worked examples.
- Explains how video compression methods exploit statistical redundancies, natural correlations, and knowledge of human perception to improve performance.
- Uses contemporary video coding standards (AVC, HEVC and VVC) as a vehicle for explaining block-based compression.
- Provides broad coverage of important topics such as visual quality assessment and video streaming.

## new to this edition
- Coverage of new, more immersive applications, explaining compression requirements and solutions for HDR and UHDTV, VR, AR, and MR.
- Description of how we can measure viewer engagement with these applications.
- An introduction to machine learning algorithms and coverage of how these can be used to optimize future compression tools.
- Inclusion of the latest advances in perceptual metrics, such as VMAF.
- Description of new and extended databases for video quality evaluation and for training machine learning systems.
- Coverage of recent innovations and standards to support adaptive video streaming.
- A review of the perceptual influences of dynamic range including descriptions of perceptual quantization and new formats.
- A comprehensive coverage of recent compression standards including AV1 and VVC.

## about the authors
**Professor David R. Bull PhD, FIET, FIEEE, CEng** obtained his BSc from the University of Exeter, his MSc from the University of Manchester and his PhD from the University of Cardiff. He currently holds the Chair in Signal Processing at the University of Bristol. He is head of the Visual Information Laboratory, Director of Bristol Vision Institute and Director of the UK Government's 46m MyWorld Strength in Places prgramme. David has worked widely across image and video processing focused on streaming, broadcast and wireless applications. He has published over 600 academic papers, various articles and 3 books and has given numerous invited/keynote lectures and tutorials. He has also received numerous awards including the IEE Ambrose Fleming Premium for his work on Primitive Operator Digital Filters a best Paper Award for his work on Link Adaptation for Video Transmission. David's work has been exploited commercially and he has acted as a consultant for companies and governments across the globe. In 2001, he co-founded ProVision Communication Technologies Ltd., who launched the world's first robust multi-source wireless HD sender for consumer use. His recent award-winning and pioneering work on perceptual video compression using deep learning, has produced world-leading rate-quality performance.

**Doctor Fan (Aaron) Zhang PhD** received the B.Sc. (Hons) and M.Sc. degrees from Shanghai Jiao Tong University (2005 and 2008 respectively), and his Ph.D from the University of Bristol (2012). He is currently a Research Fellow in the Visual Information Laboratory at the University of Bristol, working on video compression and immersive video processing. His research interests include perceptual video compression, video quality assessment and immersive video formats. Aaron has published over 50 academic papers and has contributed to two books on video compression. His work on super-resolution-based video compression, has contributed to international standardization processes and was a co-winner of the 2017 IEEE Grand Challenge on Video Compression.